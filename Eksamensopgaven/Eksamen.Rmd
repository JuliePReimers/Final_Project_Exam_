---
title: 'Sentiment analysis of danish newspapers in 1864'
author: Julie, Marchus, Nikolaj og Ditte  
date: ''
output: html_document
---

# Installing packages 

We need to install the followong packages to do textmining and sentiment analysis: 

```{r}
install.packages("here")
install.packages("pdftools")
install.packages("qpdf")
install.packages("tidytext")
install.packages("tokenizers")
install.packages("textdata")
install.packages("ggwordcloud")
```

Then we load the libraries of the packages, so they are ready to use:

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)

library(tidyverse)
library(here)
library(tidyr)
library(dplyr)

# For text mining:
library(pdftools)
library(tidytext)
library(textdata) 
library(ggwordcloud)
library(tokenizers)
library(Sentida)

```

# Uploading our dataset into R

Now it is time to load our data into R-Studio, and we do so by using the link from our mediestream search, and using the read_csv function. We define our datasæt as "data_mediestream", and now have a large dataset with all danish newspaper articles from 1864 that shows from the search: *("dybbøl" OR "slesvig" OR "Als" OR "holsten") AND "krig" AND py:1864"*

```{r}
# indhentning af data fra avisartikler fra mediestream 

data_mediestream <- read_csv("https://labs.statsbiblioteket.dk/labsapi/api/aviser/export/fields?query=%28%22dybb%C3%B8l%22%20OR%20%22slesvig%22%20OR%20%22Als%22%20OR%20%22holsten%22%29%20AND%20%22krig%22%20AND%20py%3A1864&fields=link&fields=timestamp&fields=fulltext_org&fields=familyId&fields=lplace&max=-1&structure=header&structure=content&format=CSV")


all_data <- read_csv("data/all_data_backup3.csv")
```

# Getting the information we need from the dataset 

## We want to look at newspapers published in Copenhagen, and in Ribe, Tønder and Haderslev. 

We know from looking at the tibble of our dataset, that the collumn *lplace* shows the publication place.
Firstly, we make a dataset with only the articles published in newspapers from Copenhagen, by using the filter(), and writing lplace == "København". We choose to define this Copenhagen data as *data_cph*. 


```{r}
# Find udgivelsessted for aviserne 

data_cph <- all_data %>% filter(lplace == "København")

tibble(all_data)

```

Then we do the same thing with the newspapers from Schleswig, and by using a |, we can get af new dataset of only articles published in Haderselv, Tønder or Ribe. We define this data as *data_slw*, slw being short for Schleswig.  

```{r}

data_slw <- filter(all_data, lplace == "Tønder" | lplace == "Haderslev" | lplace == "Ribe")

tibble(data_slw)

```

# Analysing the data 

We now have the datasets from Copenhagen and from Schleswig, but in order to analyse the articles, we need to look at the collumn *fulltext_org*. 

Lets look at the collumn, to see the type of data we are working with. 

```{r}

all_data %>% select(fulltext_org)

```

# Kør sentiment analyse for data
```{r}
sentiment_slw_total <- data_slw$fulltext_org %>% 
  sentida(output = "total")

sentiment_slw_mean <- data_slw$fulltext_org %>% 
  sentida(output = "mean")

```

```{r}
sentiment_cph_total <- data_cph$fulltext_org %>% 
  sentida(output = "total")

sentiment_cph_mean <- data_cph$fulltext_org %>% 
  sentida(output = "mean")

```

```{r}
sentiment_cph_total
sentiment_cph_mean

sentiment_slw_total
sentiment_slw_mean
```

